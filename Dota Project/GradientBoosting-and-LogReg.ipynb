{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv('./assets/features.csv', index_col='match_id');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выделяем \"признаки из будущего\" и удаляем их из выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "future_feature_names = [\n",
    "        'duration' \n",
    "        , 'radiant_win'\n",
    "        , 'tower_status_radiant'\n",
    "        , 'tower_status_dire'\n",
    "        , 'barracks_status_radiant'\n",
    "        , 'barracks_status_dire'\n",
    "    ]\n",
    "future_features = X[future_feature_names]\n",
    "for future_feature_name in future_feature_names:\n",
    "    del X[future_feature_name]\n",
    "\n",
    "y = future_features['radiant_win']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполняем пропуски в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_nona = X.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаём генератор разбиений для кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "kfold = KFold(n=len(X), n_folds=5, shuffle=True, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Ищем и выводим список колонок, которые имеют пропуски в значениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "* first_blood_time\n",
      "* first_blood_team\n",
      "* first_blood_player1\n",
      "* first_blood_player2\n",
      "* radiant_bottle_time\n",
      "* radiant_courier_time\n",
      "* radiant_flying_courier_time\n",
      "* radiant_first_ward_time\n",
      "* dire_bottle_time\n",
      "* dire_courier_time\n",
      "* dire_flying_courier_time\n",
      "* dire_first_ward_time\n"
     ]
    }
   ],
   "source": [
    "X_len = len(X)\n",
    "column_values_counts = ([column, X[column].count()] for column in X.columns)\n",
    "columns_with_missing_values = [col_count[0] for col_count in column_values_counts if col_count[1] != X_len]\n",
    "print 'Columns with missing values:'\n",
    "print '\\n'.join(['* ' + str(x) for x in columns_with_missing_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, следующие колонки имеют пропуски в значениях:\n",
    "* first_blood_time\n",
    "* first_blood_team\n",
    "* first_blood_player1\n",
    "* first_blood_player2\n",
    "* radiant_bottle_time\n",
    "* radiant_courier_time\n",
    "* radiant_flying_courier_time\n",
    "* radiant_first_ward_time\n",
    "* dire_bottle_time\n",
    "* dire_courier_time\n",
    "* dire_flying_courier_time\n",
    "* dire_first_ward_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Что могут означать пропуски в значениях (выберите любые две колонки)\n",
    "Пропуски в значениях первой колонки (на самом деле, первых четырёх) означают, что \"первая кровь\" была не была пролита в течение рассматриваемого нами времени.\n",
    "\n",
    "Пропуски в `radiant_bottle_time` объясняются тем, что не во всех матчах хотя бы один из игроков команд покупает эту вещь.\n",
    "\n",
    "### 1.2. Как называется столбец с целевой переменной?\n",
    "Столбец называется `radiant_win`\n",
    "### 1.3. Обучите модель для 10, 20 и 30 деревьев. Как долго проводилась кросс-валидация? Какое качество получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 10\n",
      "Score: 0.664387785223\n",
      "Time: 0:00:35.293893\n",
      "Estimators: 20\n",
      "Score: 0.682853571415\n",
      "Time: 0:01:09.926190\n",
      "Estimators: 30\n",
      "Score: 0.689496203941\n",
      "Time: 0:01:45.207535\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "for i in xrange(10, 40, 10):\n",
    "    print 'Estimators:', i\n",
    "    clf = GradientBoostingClassifier(n_estimators=i, random_state=242)\n",
    "    start_time = datetime.datetime.now()\n",
    "    mean_score = cross_val_score(clf, X_nona, y=y, cv=kfold, scoring='roc_auc').mean()\n",
    "    print 'Score:', mean_score\n",
    "    print 'Time:', datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого:\n",
    "\n",
    "* обучение 10 деревьев заняло 35 сек., среднее качество: 0.664387785223\n",
    "* 10 деревьев - 1 мин 9 сек, среднее качество: 0.682853571415\n",
    "* 30 деревьев - 1 мин 46 сек, среднее качество: 0.689496203941"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что можно сделать, чтобы ускорить его обучение при увеличении количества деревьев?\n",
    "Ответим в обратном порядке. Для того, чтобы ускорить обучение при увеличении количества деревьев, можно сделать следующие шаги:\n",
    "\n",
    "* использовать параметр `n_jobs` у `cross_val_score`, позволяющий проводить обучение параллельно.\n",
    "* определить полезность признаков и отбросить лишние с помощью параметра `clf.feature_importances_`\n",
    "* уменьшить размерность данных, например, с помощью метода главных компонент\n",
    "* ограничить глубину дерева с помощью параметра `max_depth` классификатора\n",
    "* взять для обучения только часть выборки, например, воспользовавшись функцией `train_test_split`\n",
    "\n",
    "Сделаем первое и проверим на 100 деревьях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.706327055343\n",
      "Time: 0:02:40.871921\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, random_state=242)\n",
    "start_time = datetime.datetime.now()\n",
    "mean_score = cross_val_score(clf, X_nona, y=y, cv=kfold, scoring='roc_auc', n_jobs=-1).mean()\n",
    "print 'Score:', mean_score\n",
    "print 'Time:', datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, обучение 100 деревьев заняло 2 минуты 40 секунд, среднее качество: 0.706327055343, то есть, выше, но ненамного. Целесообразность повышения количества деревьев зависит от параметров задачи, например, того, какая производительность алгоритма считается приемлимой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и подготовка данных, импорты и новый подход к измерению времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Preparing data...\n",
      "Elapsed time 0:00:00.732129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "class TimeEstimator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start_time = datetime.datetime.now()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        print 'Elapsed time', datetime.datetime.now() - self.start_time\n",
    "\n",
    "print '--> Preparing data...'\n",
    "with TimeEstimator():\n",
    "    X = pd.read_csv('./assets/features.csv', index_col='match_id')\n",
    "\n",
    "    # remove \"future\" features\n",
    "    future_feature_names = [\n",
    "        'duration'\n",
    "        , 'radiant_win'\n",
    "        , 'tower_status_radiant'\n",
    "        , 'tower_status_dire'\n",
    "        , 'barracks_status_radiant'\n",
    "        , 'barracks_status_dire'\n",
    "    ]\n",
    "    future_features = X[future_feature_names]\n",
    "    for future_feature_name in future_feature_names:\n",
    "        del X[future_feature_name]\n",
    "\n",
    "    y = future_features['radiant_win']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Набор функций, используемый для обработки данныx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cols_by_regex(all_cols, col_regex):\n",
    "    r = re.compile(col_regex)\n",
    "    col_match = np.vectorize(lambda x: x if bool(r.match(x)) else None)\n",
    "    return [col for col in col_match(all_cols) if col is not None and col != 'None']\n",
    "\n",
    "\n",
    "# returns numpy array\n",
    "def fill_na_and_scale_features(x):\n",
    "    print 'Scaling features...'\n",
    "    x_nona = x.fillna(0)\n",
    "    with TimeEstimator():\n",
    "        scaler = StandardScaler()\n",
    "        return scaler.fit_transform(x_nona)\n",
    "\n",
    "\n",
    "def build_data_with_pick(x):\n",
    "    print '--> Building pick information...'\n",
    "    with TimeEstimator():\n",
    "        # search for heroes\n",
    "        hero_cols = get_cols_by_regex(x.columns, '.*_hero$')\n",
    "        heroes = set()\n",
    "        for col in hero_cols:\n",
    "            col_heroes = x[col].unique()\n",
    "            for hero_number in col_heroes:\n",
    "                heroes.add(hero_number)\n",
    "\n",
    "        print '--> Number of heroes: ', len(heroes)\n",
    "\n",
    "        # build pick information\n",
    "        pick_arr = np.zeros((x.shape[0], max(heroes) + 1))\n",
    "        for i, match_id in enumerate(x.index):\n",
    "            pick_arr[i, 0] = match_id\n",
    "            for p in xrange(5):\n",
    "                pick_arr[i, x.ix[match_id, 'r%d_hero' % (p + 1)]] = 1\n",
    "                pick_arr[i, x.ix[match_id, 'd%d_hero' % (p + 1)]] = -1\n",
    "\n",
    "        # build pick column labels, create data frame\n",
    "        new_cols = ['match_id'] + map(lambda col: 'hero_' + str(col), xrange(1, max(heroes) + 1))\n",
    "        pick_df = pd.DataFrame(data=pick_arr, columns=new_cols, index=pick_arr[:, 0])\n",
    "\n",
    "        # concatenate pick data frame to the main data\n",
    "        x_pick = pd.concat([x, pick_df], axis=1)\n",
    "        return x_pick\n",
    "\n",
    "# Does cross-validation with optional search of the best value for parameter C\n",
    "def cross_val_on(x, y, calc_c=False):\n",
    "    x_scaled = fill_na_and_scale_features(x)\n",
    "    print 'Doing cross-validation...'\n",
    "\n",
    "    with TimeEstimator():\n",
    "        grid = {\n",
    "            'C': np.power(10.0, np.arange(-5, 6))\n",
    "        }\n",
    "        kfold = KFold(n=y.size, n_folds=5, shuffle=True, random_state=241)\n",
    "\n",
    "        if calc_c:\n",
    "            clf = LogisticRegression(penalty='l2', random_state=241)\n",
    "            grid_search = GridSearchCV(clf, grid, cv=kfold, scoring='roc_auc', n_jobs=-1)\n",
    "            grid_search.fit(x_scaled, y)\n",
    "            best_score = 0\n",
    "            best_c = 0\n",
    "            for a in grid_search.grid_scores_:\n",
    "                if a.mean_validation_score > best_score:\n",
    "                    best_score = a.mean_validation_score\n",
    "                    best_c = a.parameters['C']\n",
    "            print 'Best mean score: ', best_score, 'C:', best_c\n",
    "            return best_c\n",
    "        else:\n",
    "            # Know C=0.01 is the best\n",
    "            C = 0.01\n",
    "            clf = LogisticRegression(random_state=241, C=C)\n",
    "            mean_score = cross_val_score(clf, x_scaled, y=y, cv=kfold, scoring='roc_auc', n_jobs=-1).mean()\n",
    "            print 'Mean score: ', mean_score\n",
    "            return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Какое качество получилось у логистической регрессии над всеми исходными признаками? Чем можно объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training regression on raw data...\n",
      "Scaling features...\n",
      "Elapsed time 0:00:00.142610\n",
      "Doing cross-validation...\n",
      "Mean score:  0.716341465365\n",
      "Elapsed time 0:00:05.305648\n",
      "Best C:  0.01\n"
     ]
    }
   ],
   "source": [
    "print '--> Training regression on raw data...'\n",
    "cross_val_on(X, y, calc_c=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, получилось 0.716341465365, что примерно на 3.8% выше, чем у градиентного бустинга. Предположительно, разница объясняется неплохой линейной разделимостью выборки. Кросс-валидация по 5 блокам заняла 5 секунд. Время на 30 вершинах градиентного бустинга 1 мин 46 сек, т.е. примерно в 30 раз больше. Причём для логистической регрессии параметр n_jobs существенно на скорость не влияет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем можно объяснить это изменение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training on non-categorial features...\n",
      "Scaling features...\n",
      "Elapsed time 0:00:00.130356\n",
      "Doing cross-validation...\n",
      "Mean score:  0.716400950653\n",
      "Elapsed time 0:00:04.803799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print '--> Training on non-categorial features...'\n",
    "non_categ_cols = get_cols_by_regex(X.columns, '^(?!(.*_hero$|^lobby_type$)).*')\n",
    "X_no_categ = X[non_categ_cols]\n",
    "cross_val_on(X_no_categ, y, calc_c=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка качества: 0.716400950653, время: 4 сек. Получили небольшой прирост качества и скорости. Причиной увеличения качества является неправильное использование признаков, создававшее шум. Причиной прироста скорости является уменьшение размерности пространства признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3, 2.4 Cколько различных идентификаторов героев существует в данной игре? Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Building pick information...\n",
      "--> Number of heroes:  108\n",
      "Elapsed time 0:00:04.192704\n",
      "--> Training on full data set with pick columns (just for fun)...\n",
      "Scaling features...\n",
      "Elapsed time 0:00:00.287462\n",
      "Doing cross-validation...\n",
      "Mean score:  0.751908999986\n",
      "Elapsed time 0:00:10.148128\n",
      "--> Training on pick data set without categ columns...\n",
      "Scaling features...\n",
      "Elapsed time 0:00:00.276818\n",
      "Doing cross-validation...\n",
      "Best mean score:  0.751969165698 C: 0.01\n",
      "Elapsed time 0:01:38.514678\n",
      "Best C:  0.01\n"
     ]
    }
   ],
   "source": [
    "X_pick = build_data_with_pick(X)\n",
    "\n",
    "print '--> Training on full data set with pick columns (just for fun)...'\n",
    "cross_val_on(X_pick, y, calc_c=False)\n",
    "\n",
    "# recalculate non-category columns due to changed data set\n",
    "pick_non_categ_cols = get_cols_by_regex(X_pick.columns, '^(?!(.*_hero$|^lobby_type$)).*')\n",
    "X_pick_no_categ = X_pick[pick_non_categ_cols]\n",
    "\n",
    "print '--> Training on pick data set without categ columns...'\n",
    "best_C = cross_val_on(X_pick_no_categ, y, calc_c=True)\n",
    "print 'Best C: ', best_C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, в играх из файла участвовало 108 различных героев. Качество после добавления мешка слов составило 0.751969165698. Прирост качества связан с тем, что информация об участвующих в игре героях важна с точки зрения победы в игре, и поэтому добавление её в выборку в правильной форме улучшает линейную разделимость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?\n",
    "Для ответа на вопрос подготовим данные из выборки аналогичным описанному выше способом, удалив из них категориальные признаки и добавив \"мешок слов\" по героям. После этого используем найденное лучшее значение для константы C, чтобы обучить классификатор и сделать предсказание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training on pick data set without categ columns...\n",
      "Scaling features...\n",
      "Elapsed time 0:00:00.275432\n",
      "Doing cross-validation...\n",
      "Best mean score:  0.751969165698 C: 0.01\n",
      "Elapsed time 0:01:42.926424\n",
      "Best C:  0.01\n",
      "--> Fitting regression with best c...\n",
      "Scaling features...\n",
      "Elapsed time 0:00:00.275856\n",
      "Fitting...\n",
      "Elapsed time 0:00:03.953320\n",
      "--> Loading and preparing test data...\n",
      "--> Building pick information...\n",
      "--> Number of heroes:  108\n",
      "Elapsed time 0:00:00.786651\n",
      "Scaling features...\n",
      "Elapsed time 0:00:00.050387\n",
      "--> Predicting...\n",
      "Elapsed time 0:00:00.015273\n",
      "--> Min predicted value:  0.00859504107819 Max predicted value:  0.996403192335\n"
     ]
    }
   ],
   "source": [
    "print '--> Fitting regression with best c...'\n",
    "fit_clf = LogisticRegression(penalty='l2', C=best_C, random_state=241)\n",
    "X_to_fit = fill_na_and_scale_features(X_pick_no_categ)\n",
    "print 'Fitting...'\n",
    "with TimeEstimator():\n",
    "    fit_clf.fit(X_to_fit, y)\n",
    "\n",
    "print '--> Loading and preparing test data...'\n",
    "X_test = pd.read_csv('./assets/features_test.csv', index_col='match_id')\n",
    "X_test_with_pick = build_data_with_pick(X_test)\n",
    "X_test_pick_no_categ = X_test_with_pick[pick_non_categ_cols]\n",
    "X_test_scaled = fill_na_and_scale_features(X_test_pick_no_categ)\n",
    "print '--> Predicting...'\n",
    "with TimeEstimator():\n",
    "    predictions = fit_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "print '--> Min predicted value: ', predictions.min(), 'Max predicted value: ', predictions.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого:\n",
    "\n",
    "* минимальное значение: 0.00859504107819\n",
    "* максимальное значение: 0.996403192335"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
